#!/usr/bin/env python3
"""
Test script to verify edge format consistency after fixes
"""

import sys
import os
sys.path.append(os.path.dirname(__file__))

from core.extract import create_connectivity_repair_prompt, extract_connectivity_relationships
from core.disconnection_repair import ConnectionInferenceEngine, LLMDisconnectionRepairer

def test_connectivity_repair_format():
    """Test that connectivity repair generates consistent edge format"""
    print("Testing connectivity repair prompt format...")
    
    # Mock disconnected entities 
    disconnected_entities = [
        {
            'id': 'test_condition',
            'type': 'Condition',
            'description': 'Test condition for connectivity repair'
        }
    ]
    
    # Create prompt
    prompt = create_connectivity_repair_prompt(
        "Test text about colonial resistance and geographic distance enabling autonomy.",
        disconnected_entities,
        "Main graph with Events and Hypotheses",
        None
    )
    
    # Check prompt format
    if '"source_id":' in prompt and '"target_id":' in prompt:
        print("[PASS] Connectivity repair prompt uses source_id/target_id format")
        return True
    else:
        print("[FAIL] Connectivity repair prompt still uses wrong format")
        print("Prompt content:")
        print(prompt[-500:])  # Show last 500 chars
        return False

def test_inference_engine_format():
    """Test that inference engine generates consistent edge format"""
    print("\nTesting inference engine edge format...")
    
    # Mock graph data
    mock_graph = {
        'nodes': [
            {'id': 'test_condition', 'type': 'Condition', 'properties': {'description': 'geographic distance'}},
            {'id': 'test_event', 'type': 'Event', 'properties': {'description': 'colonial resistance'}}
        ],
        'edges': []
    }
    
    engine = ConnectionInferenceEngine()
    inferred_edges = engine.infer_missing_connections(mock_graph)
    
    if inferred_edges:
        first_edge = inferred_edges[0]
        if 'source_id' in first_edge and 'target_id' in first_edge:
            print("[PASS] Inference engine generates source_id/target_id format")
            return True
        else:
            print("[FAIL] Inference engine generates wrong format:")
            print(f"Edge keys: {list(first_edge.keys())}")
            return False
    else:
        print("[INFO] No edges generated by inference engine")
        return True

def test_llm_repairer_format():
    """Test that LLM repairer uses consistent format in prompts"""
    print("\nTesting LLM repairer prompt format...")
    
    repairer = LLMDisconnectionRepairer()
    
    # Check the template
    template = repairer.enhanced_repair_prompt_template
    
    if '"source_id":' in template and '"target_id":' in template:
        print("[PASS] LLM repairer uses source_id/target_id format in prompts")
        return True
    else:
        print("[FAIL] LLM repairer uses wrong format in prompts")
        return False

def main():
    """Run all format consistency tests"""
    print("="*60)
    print("EDGE FORMAT CONSISTENCY TEST")
    print("="*60)
    
    results = []
    
    # Test all components
    results.append(test_connectivity_repair_format())
    results.append(test_inference_engine_format())
    results.append(test_llm_repairer_format())
    
    print("\n" + "="*60)
    print("RESULTS SUMMARY")
    print("="*60)
    
    if all(results):
        print("[SUCCESS] ALL TESTS PASSED - Edge format consistency fixed!")
        return 0
    else:
        print("[ERROR] Some tests failed - Edge format issues remain")
        return 1

if __name__ == "__main__":
    exit(main())